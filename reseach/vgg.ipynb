{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. PyTorch can use the GPU.\n",
      "Number of available GPUs: 1\n",
      "Current GPU device: 0\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. PyTorch can use the GPU.\")\n",
    "    print(\"Number of available GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Current GPU device:\", torch.cuda.current_device())\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Before starting the training loop\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"C:/Users/91623/Desktop/Brain_tumor_research/Data\"\n",
    "train_path = \"C:/Users/91623/Desktop/Brain_tumor_research/Data/Training\"\n",
    "test_path = \"C:/Users/91623/Desktop/Brain_tumor_research/Data/Testing\"\n",
    "image_size = (256,256)\n",
    "num_classes = 5\n",
    "train_paths = glob(f\"{train_path}/*/*.jpg\")\n",
    "test_paths = glob(f\"{test_path}/*/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91623\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91623\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to C:\\Users\\91623/.cache\\torch\\hub\\checkpoints\\vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 548M/548M [00:09<00:00, 62.4MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.4885, Train Accuracy: 25.47%\n",
      "Epoch 1/10, Validation Loss: 1.5142, Validation Accuracy: 22.88%\n",
      "Epoch 2/10, Train Loss: 1.4883, Train Accuracy: 25.51%\n",
      "Epoch 2/10, Validation Loss: 1.5142, Validation Accuracy: 22.88%\n",
      "Epoch 3/10, Train Loss: 1.4879, Train Accuracy: 25.51%\n",
      "Epoch 3/10, Validation Loss: 1.5142, Validation Accuracy: 22.88%\n",
      "Epoch 4/10, Train Loss: 1.4886, Train Accuracy: 25.51%\n",
      "Epoch 4/10, Validation Loss: 1.5142, Validation Accuracy: 22.88%\n",
      "Epoch 5/10, Train Loss: 1.4890, Train Accuracy: 25.51%\n",
      "Epoch 5/10, Validation Loss: 1.5142, Validation Accuracy: 22.88%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 121\u001b[0m\n\u001b[0;32m    118\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m--> 121\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m validate_epoch()\n\u001b[0;32m    124\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
      "Cell \u001b[1;32mIn[6], line 79\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     78\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 79\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[0;32m     82\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 4\n",
    "\n",
    "# Load the VGG19 model with pre-trained weights\n",
    "def create_base_model_from_vgg19():\n",
    "    model_vgg19 = models.vgg19(pretrained=True)\n",
    "    # Freeze the existing weights\n",
    "    for param in model_vgg19.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model_vgg19\n",
    "\n",
    "# Add custom layers to the VGG19 base model\n",
    "class CustomVGG19(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomVGG19, self).__init__()\n",
    "        self.vgg19 = create_base_model_from_vgg19()\n",
    "        self.vgg19.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.vgg19.features(x)\n",
    "        x = self.vgg19.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.vgg19.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = CustomVGG19(num_classes=num_classes).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=3, min_lr=0.001)\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = ImageFolder(root=train_path, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dataset = ImageFolder(root=test_path, transform=test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Training function\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_accuracy = total_correct / total_predictions\n",
    "    \n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "# Validation function\n",
    "def validate_epoch():\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    avg_accuracy = total_correct / total_predictions\n",
    "    \n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train_epoch()\n",
    "    val_loss, val_accuracy = validate_epoch()\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy*100:.2f}%')\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
